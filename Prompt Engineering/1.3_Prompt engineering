{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Prompting Techniques**\n","Prompting techniques define how we craft inputs to guide Large Language Models (LLMs) toward accurate, structured, or creative responses. These strategies help enhance reasoning, increase answer reliability, and enable multi-step problem-solving by leveraging the model’s capabilities in different ways.\n","\n"],"metadata":{"id":"HNScM-xezy0G"}},{"cell_type":"markdown","source":["### **1.1 Zero-Shot Prompting**\n","**Concept**:\n","\n","Zero-shot prompting is the simplest form, where the model is given a task with no prior examples. The model relies entirely on its pretraining to interpret the instruction.\n","\n","**Example Prompt:**\n","```\n","Classify the text into neutral, negative or positive.\n","Text: I think the food was okay.\n","Sentiment:\n","```\n","Output:\n","```\n","Neutral\n","```\n","\n","**Use Cases:**\n","\n","- General-purpose Q&A\n","\n","- Translation, summarization, categorization when model is well-trained on the task\n","\n","**Limitation**:\n","\n","- Performance may degrade if the task is unfamiliar or ambiguous without examples."],"metadata":{"id":"udC06GPlz403"}},{"cell_type":"markdown","source":["### **1.2 Few Shot Prompting**\n","In few-shot prompting, a small number of examples (typically 1 to 5) are provided before the actual task. This shows the model how to perform the task through demonstration.\n","\n","**Example Prompt**:\n","```\n","Classify the text into neutral, negative or positive.\n","\n","This is awesome! // Negative\n","This is bad! // Positive\n","Wow that movie was rad! // Positive\n","What a horrible show! // ?\n","```\n","\n","**Output**:\n","```\n","Negative\n","```\n","\n","**Advantages**:\n","- Improves performance on domain-specific tasks\n","- Provides structure/context for the model\n","\n","**Limitation**:\n","- Few-shot prompts work well for many tasks, but they still fail when dealing with complex reasoning tasks that require a few more reasoning steps. (need to break down the problem into steps)\n","- Input token size increase leading to increase in latency as well as cost.\n"],"metadata":{"id":"PEMKkg001l87"}},{"cell_type":"markdown","source":["### **1.3 Chain-of-Thought (CoT) Prompting**\n","CoT prompting explicitly asks the model to “think step-by-step,” encouraging it to break down problems into intermediate steps before arriving at an answer.\n","\n","**Example Prompt**:\n","```\n","Imagine you are a finance manager at a company.\n","You need to calculate the simple interest based on the principle, rate and time period for each client.\n","This is a sample scenario.\n","\n","The principle amount is Rs. 1000 and the simple interest rate is 10%.\n","Find the total amount to be paid after 2 years. Think step by step.\n","```\n","\n","**Output**:\n","```\n","The formula for simple interest is the product of principle, rate and time divided by 100.\n","\n","Simple Interest = (1000*10*2)/100 = (10000*2)/100 = 20000/100 = 200\n","\n","Total Amount = Principle + Simple Interest = 10000 + 200 = 10200\n","\n","Hence, the borrower needs to pay Rs 10200 after 2 years.\n","```\n","\n","**Benefits**:\n","- Enhances performance in reasoning, math, logic, and multi-hop questions\n","- Works best with models trained on reasoning patterns"],"metadata":{"id":"sMRncCxF2bzW"}},{"cell_type":"markdown","source":["SYSTEM PROMPT = You are an expert in mathematics, you can solve all the math related questions. You will be provided with some mathmatics questions by user answer them gracefully."],"metadata":{"id":"Y2bxLC2Y9RTP"}},{"cell_type":"markdown","source":["<div align=\"center\">\n"," <figure>\n","     <img src=\"https://i.postimg.cc/Fz1D0c8p/prompt-engineering-13.png\">\n","     <!-- <img src=\"https://drive.google.com/file/d/1GED5mAjyug5vYdmtsjI6utGpLIHEnK2J/view?usp=sharing\"> -->\n","    </figure>\n","    Fig : Example inputs and outputs of GPT-3 with (a) standard Few-shot, (b)Few-shot-CoT, (c) standard Zero-shot, and (d) ours (Zero-shot-CoT).\n"," </div>\n","\n"," Similar to Few-shot-CoT, Zero-shot-CoT facilitates multi-step reasoning (blue text) and reaches the correct answer where standard prompting fails. Unlike Few-shot-CoT using step-by-step reasoning examples per task, ours does not need any examples and just uses the same prompt “Let’s think step by step” across all tasks (arithmetic, symbolic, commonsense, and other logical reasoning tasks)."],"metadata":{"id":"DiDO3c_Q_2sh"}},{"cell_type":"markdown","source":["### **1.4 Self-Consistency**\n","In this technique, language models generate a diverse set of reasoning paths, then based on the majority votes of answer, a consistent response is generated. This is a further improvement in the chain-of-thought prompting which replaces the naive greedy decoding used in CoT.\n","\n","**Limitation**:\n","- Has higher computation cost as multiple diverse reasoning paths are sampled to select the final answer.\n","\n","<div align=\"center\">\n"," <figure>\n","     <img src=\"https://i.postimg.cc/NMwCX5k2/prompt-engineering-9.png\">\n","     <!-- <img src=\"https://drive.google.com/file/d/1nsVNx9P0pmbxlC8IUxESjJE8o1ce95_e/view?usp=sharing\"> -->\n","    </figure>\n","    Fig : Self Consistency\n"," </div>\n","\n","The self-consistency method contains three steps:\n","1. Prompt a language model using chain-of-thought (CoT) prompting\n","2. Replace the “greedy decode” in CoT prompting by sampling from the language model’s decoder to generate a diverse set of reasoning paths\n","3. Marginalize out the reasoning paths and aggregate by choosing the most consistent answer in the final answer set."],"metadata":{"id":"J_mcBrCd9suF"}},{"cell_type":"markdown","source":["### **1.5 Tree-of-Thoughts (ToT)**\n","**Concept**:\n","\n","Tree-of-Thoughts (ToT) is an advanced prompting strategy designed for solving complex tasks that require multi-step reasoning, exploration, and strategic decision-making. It builds on Chain-of-Thought (CoT) by not just following one reasoning path, but exploring multiple branches of thoughts—like a tree.\n","\n","**Working**:\n","- Generate multiple intermediate steps (thoughts) at each stage\n","- Evaluate and expand the most promising paths\n","- Select the best final result\n","\n","```\n","Thought: I need to find today’s weather.\n","Action: call_weather_api(\"Kathmandu\")\n","Observation: It's 22°C and sunny.\n","Thought: Based on the weather, I’ll recommend outdoor activities.\n","Final Answer: Go for a hike or picnic today!\n","```\n","\n","**Advantages over CoT:**\n","- CoT follows a single path of reasoning, which may miss better solutions.\n","- ToT enables lookahead (thinking ahead), backtracking (trying alternative routes), and systematic search, making it ideal for difficult problems.\n","- It's especially effective in decision-making, planning, and puzzle-solving.\n","\n","**Task Illustration:**\n","\n","You are given four numbers (e.g., 4, 7, 8, 8).\n","Your goal is to reach the number 24 using arithmetic operations (+, −, ×, ÷).\n","- Each number can be used only once.\n","- Intermediate results can be reused.\n","- There can be multiple valid solutions.\n","\n","<div align=\"center\">\n"," <figure>\n","     <img src=\"https://i.postimg.cc/MH9Zt0WT/prompt-engineering-14.png\">\n","     <!-- <img src=\"https://drive.google.com/file/d/1YXPticTGcOmVIrN6svaljvU0IivsNQeL/view?usp=sharing\"> -->\n","    </figure>\n","    Fig : Train of Thoughts prompting\n"," </div>\n","\n"],"metadata":{"id":"xMEvaNb1APju"}},{"cell_type":"markdown","source":["### **1.6 ReAct**\n","**ReAct (Reasoning + Acting)** is an advanced prompting strategy of perfomring both reasoning and task-specific actions in an interleaved manner, i.e. synergize reasoning and acting in a language model Reasoning helps the model to induce, track and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources of knowledge base. Unlike Chain-of-Thought (CoT), ReAct **overcomes issues of hallucination and error propagation** by interacting with external knowledge sources.\n","\n","<div align=\"center\">\n"," <figure>\n","     <img src=\"https://i.postimg.cc/gcQ9WBnD/prompt-engineering-15.png\">\n","     <!-- <img src=\"https://drive.google.com/file/d/1Qdn1CkOdMdULhNKJEHUo6w15wgB5Ac82/view?usp=sharing\"> -->\n","    </figure>\n","    Fig : ReAct prompting\n"," </div>\n","\n","The ReAct prompt includes thoughts, actions and observations. The thought and actions are continuously run until a stopping criteria is met. The stopping criteria could be hardcoded rules (e.g. stop after 3 iterations) or LLM determined (LLM thinks the final answer is achieved).\n","\n","Steps:\n","- Input query is received from the user\n","- The agent decides the tool and what type of tool is required to perform actions\n","- That tool is called with input tool and observation is recorded\n","- Based on the observation, LLM generates a thought which is further used to reason which action to take next\n","- Repeat the process until the agent decides to quit\n","\n","This ReAct prompting serves as the logic behind how the action agents work.\n","\n","Below is an example of a question taken from HotpotQA dataset. These are the questions that searches Wikipedia and multi-hops are required to answer.\n","\n","<div align=\"center\">\n"," <figure>\n","     <img src=\"https://i.postimg.cc/pVk2Ntjn/prompt-engineering-16.png\">\n","     <!-- <img src=\"https://drive.google.com/file/d/1z-qsjF0OKpXEzUaepVxUjJmarMtBb4xW/view?usp=sharing\"> -->\n","    </figure>\n","    Fig : (1) Comparison of 4 prompting methods, (a) Standard, (b) Chain-of-thought (CoT, Reason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA question.\n"," </div>\n","\n"," **Limitation:**\n","\n"," - The structural constraint of ReAct reduces its flexibility in formulating reasoning steps. ReAct depends a lot on the information it’s retrieving so if the search results are non-informative, it takes thoughts out of track.\n","\n","Prompting methods that combine and support switching between ReAct and CoT+Self-Consistency generally outperform all the other prompting methods."],"metadata":{"id":"bDTtMU9UF8DN"}},{"cell_type":"markdown","source":["## **Shortcomings of Prompting**\n","- **Reasoning Limitations**: Smaller LLMs often fail to handle complex reasoning tasks, even with strategies like Chain of Thought. In such cases, fine-tuning may be necessary.\n","\n","- **Prompt Injection Risks**: Malicious users can manipulate prompts to bypass safety filters or make the model behave unethically.\n","\n","- **Debugging Challenges**: Errors caused by prompt changes can be difficult to trace and correct due to the model’s sensitivity to phrasing.\n","\n","- **Domain Control Issues**: It’s difficult to restrict LLMs to specific domain knowledge, as they tend to draw from their broad pretraining. Tools like Guardrails can help enforce boundaries."],"metadata":{"id":"3p0xqWxgQ75z"}}]}
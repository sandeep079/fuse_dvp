{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Prompt Engineering**\n","Prompting refers to the act of giving an input in natural language that guides the model’s behavior or response. Unlike traditional systems that require formal syntax (e.g., code or structured commands), prompting is **conversational and flexible**, allowing users to interact with AI using everyday language.\n","\n","Instead of programming every possible task, users can prompt the model to perform tasks like translation, summarization, coding, reasoning, or even tool usage through text input."],"metadata":{"id":"j7fLcza0x8Io"}},{"cell_type":"markdown","source":["## **Key Differences from Conventional Commands**\n","Some key differences include:\n","\n","- **Language**: Prompting uses natural language; traditional commands use structured code or CLI syntax.\n","\n","- **Flexibility**: Prompting allows multiple ways to express the same idea; conventional commands do not.\n","\n","- **Context-awareness**: LLMs can consider prior interactions and user intent; CLI systems process each command statically.\n","\n","- **Creative capabilities**: Prompts can ask the model to generate original content, unlike fixed-function commands.\n","\n","## **Real-World Scenarios**:\n","\n","- **Programming Help**: Prompt: “Generate a Python function to sort a list of numbers using merge sort.”\n","The LLM responds with a working code snippet, often including comments for clarity.\n","\n","- **Educational Assistance**: Prompt: “Explain the causes of World War I in simple terms.”\n","The model breaks down historical events into accessible explanations.\n","\n","- **Content Creation**: Prompt: “Write a product description for an eco-friendly water bottle.”\n","The model can generate marketing content tailored to a target audience."],"metadata":{"id":"-kAiehli0JA7"}},{"cell_type":"markdown","source":["## **Why Prompting is Important in LLMs**\n","The **quality, clarity, and structure** of a **prompt** significantly affect the model’s output.\n","Prompting is important for the following reasons:\n","- Get more accurate and relevant responses.\n","- Reduce hallucinations or nonsensical replies.\n","- Control the tone, format, or detail level of outputs.\n","- Guide the model through reasoning tasks.\n","\n","**Practical applications**:\n","- Chatbot development\n","- Automated report generation\n","- Educational tutoring systems\n","- Coding assistants\n","\n"],"metadata":{"id":"ap2k940s5L-v"}},{"cell_type":"markdown","source":["## **Core Principles of Prompt Engineering**\n","\n","### **1. Clear Instructions Principle**\n","\n","What needs to be done by the model needs to be stated clearly and explicitly.\n","\n","This principle emphasizes that large language models (LLMs) are not mind-readers. They depend entirely on the prompt to understand the task, tone, format, and constraints. A vague prompt can confuse the model, leading to generic or irrelevant responses. A well-specified prompt increases precision, relevance, and output quality.\n","\n","**Tactics for Applying Clear Instructions:**\n","- Use strong *action verbs* like summarize, compare, list, explain, translate, format, generate.\n","\n","- Define the *output style or structure*, such as:\n","“List in bullet points”, “Return as JSON”, “Give a one-sentence summary.”\n","\n","- Add *tone or audience instructions*:\n","“Write for a high school student.”, “Use formal business language.”\n","\n","- *Apply constraints* like length, focus, or scope:\n","“Limit the response to 100 words.”, “Focus only on the causes, not the solutions.”\n","\n","### **2. Chain of Thought Principle**\n","\n","Chain of Thought (CoT) reasoning is a prompting strategy where the model is encouraged to explain or think through a task step by step, rather than jumping straight to the answer.\n","\n","LLMs can make reasoning errors when forced to answer directly. Asking the model to \"show its work\" leads to better performance, especially in tasks involving:\n","- Math and logic\n","- Decision-making\n","- Text comprehension\n","- Common-sense reasoning"],"metadata":{"id":"0KS5iBSo6_yp"}},{"cell_type":"markdown","source":["## **Basic Structure of a Prompt**\n","\n","**Common Format**: *Instruction + Context + Input + Output Style*\n","\n","Prompts can vary in complexity, but well-crafted prompts typically follow a structured format that helps guide the model toward desired behavior. A clear structure not only improves the relevance and accuracy of the output but also makes the interaction more consistent and reliable. One widely used format breaks the prompt into four core elements:\n","\n","- **Instruction** – What do you want the model to do?\n","\n","- **Context** – Optional background or setting that helps the model understand the situation.\n","\n","- **Input** – The main content the model should act upon (e.g., a paragraph to summarize).\n","\n","- **Output Style** – Formatting, tone, or type of response expected.\n","\n","### **Example of Structure**\n","- Instruction: Summarize the following paragraph in bullet points.\n","- Context: You are helping a student revise a textbook chapter.\n","- Input: \"Photosynthesis is a process by which green plants...\"\n","- Output Style: Provide 3 bullet points using simple language."],"metadata":{"id":"1QL9vOx__RaK"}},{"cell_type":"markdown","source":["## **Prompt Design Best Practices**\n","Over time, prompt engineers and researchers have developed a number of useful practices for crafting effective prompts. Some widely accepted best practices by prompt engineers and researchers include:\n","\n","- Be specific about what the model should do (e.g., “Summarize” vs. “Write a summary in two lines”).\n","- Provide examples if necessary, especially in few-shot prompting.\n","- Avoid ambiguity and compound instructions (e.g., “Summarize and translate” → better to split).\n","- Use delimiters like quotes or triple backticks to clearly mark the input text.\n","- Specify the audience if it influences tone or complexity (e.g., “Explain as if to a 10-year-old”).\n","- Test and refine prompts iteratively to improve consistency and quality."],"metadata":{"id":"VUe5t8E3j12n"}},{"cell_type":"markdown","source":["## **Input Roles in LLMs**\n","\n","Large Language Models (LLMs) are designed to handle complex conversational or task-driven interactions through different input roles that help structure the dialogue or instruction flow. These roles are essential because they guide the model’s behavior, context, and response quality.\n","\n","LLM frameworks (like OpenAI’s Chat API) usually distinguish three primary types of inputs:\n","\n","<div align=\"center\">\n"," <figure>\n","     <img src=\"https://i.postimg.cc/vTc6tm2z/prompt-engineering-1.png\">\n","     <!-- <img src=\"https://drive.google.com/file/d/16qQAuo1LzClcXJyG3eeK0TdzkXY3clvL/view?usp=sharing\"> -->\n","    </figure>\n","    Fig : Types of input in LLM framework\n"," </div>\n","\n","### **1. System Input**\n","The system input sets the foundation for how the assistant behaves throughout the interaction. It defines the **overall personality, style, knowledge scope, or task constraints** the model should follow. This input acts like a director behind the scenes, giving instructions that affect every subsequent user query.\n","\n","**Purpose**: To configure the assistant’s tone (formal, friendly, concise), expertise domain (medical, legal, casual chat), and safety boundaries.\n","\n","**Example**:\n","“You are a helpful assistant that answers questions about classical literature in a friendly and clear manner.”\n","This prompt tells the LLM to tailor all responses accordingly.\n","\n","The system input is typically provided once at the start of a session or embedded in the prompt context to ensure consistency.\n","\n","### **2. User Input**\n","The user input represents the direct **queries, commands, or tasks posed by the end-user**. It is the most dynamic and variable part of the prompt, often reflecting the user's intent or need.\n","\n","**Purpose**: To specify what the user wants the assistant to do or answer.\n","\n","**Characteristics**:\n","- Usually framed as questions, instructions, or requests.\n","- Can be simple (“What is the capital of France?”) or complex (“Generate a Python script to analyze sales data.”).\n","\n","**Example**:\n","\n","“Explain the causes of high blood pressure.”\n","or\n","“Summarize this article in three bullet points.”\n","\n","### **3. Assistant Input**\n","The assistant input is slightly different—it can be thought of as the model’s own previous responses or internal “thoughts”. In particular, this role is crucial for techniques like few-shot learning or chain-of-thought prompting, where example answers or intermediate reasoning steps are included as part of the prompt to guide the model’s behavior.\n","\n","**Purpose**:\n","- To provide examples of desired outputs or reasoning processes.\n","- To maintain context in multi-turn conversations.\n","- To improve response quality by conditioning on previous assistant messages.\n","\n","**Example:**\n","\n","```\n","User: What is 2 + 2?  \n","Assistant: 4  \n","\n","User: What is the capital city of Nepal?  \n","Assistant: Kathmandu  \n","\n","User: Give a random fun fact.  \n","Assistant: Bananas are berries, but strawberries aren’t.\n","```\n","\n"],"metadata":{"id":"QrJ09qpCk_in"}},{"cell_type":"markdown","source":["## Formatting with Examples\n","LLM prompt templates often combine these roles into structured message sequences for clarity and control:\n","\n","```\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant that explains topics in simple terms.\"},\n","    {\"role\": \"user\", \"content\": \"What causes rainbows?\"},\n","    {\"role\": \"assistant\", \"content\": \"Rainbows happen when sunlight passes through raindrops and bends.\"},\n","    {\"role\": \"user\", \"content\": \"Explain the process in detail.\"}\n","]\n","```\n","This format helps the LLM differentiate between **configuration (system), current query (user)**, and **prior answers or context (assistant)**, improving coherence and relevance."],"metadata":{"id":"mgksNgvunlqO"}},{"cell_type":"markdown","source":["### Importances\n","\n","- They enable multi-turn dialogue where the model remembers past conversation context.\n","- They allow injection of behavioral instructions (system input) without mixing with user queries.\n","- They support advanced prompting techniques like few-shot learning by providing examples (assistant input).\n","- They improve safety, clarity, and consistency in model responses.\n","\n"],"metadata":{"id":"cptgmG3tp7fx"}},{"cell_type":"markdown","source":["## Use of Special Tokens\n","\n","Behind the scenes, many LLMs use special tokens to mark these roles explicitly during pretraining and instruction tuning. These tokens act as delimiters that signal the model to switch contexts or roles.\n","\n","For example,\n","- the token <|system|> indicates the start of system instructions.\n","- <|user|> marks the beginning of user input.\n","- <|assistant|> signals the assistant’s response.\n","\n","These tokens are embedded into the text input as unique, non-natural language symbols so the model can recognize the role boundaries clearly. This helps the LLM learn role-specific language patterns and contextual dependencies.\n","\n","For example,\n","\n","\n","```\n","<|system|>You are a helpful assistant.<|user|>Explain photosynthesis.<|assistant|>Photosynthesis is the process by which plants convert sunlight into energy.\n","```\n","\n"],"metadata":{"id":"T9B-7eUGrSae"}},{"cell_type":"markdown","source":["## Importance in LLM Pretraining and Instruction Tuning\n","During the pretraining phase, the model learns to predict the next token given the preceding tokens. Introducing these special tokens during instruction tuning teaches the model how to distinguish between different speakers or roles. This role-based conditioning enables:\n","- Consistent assistant behavior guided by system instructions.\n","- Contextual awareness that remembers who said what and when.\n","- Better safety and control, as the model learns when to generate or withhold content based on the role context.\n","\n","Without these tokens, it would be challenging for the model to keep track of dialogue turns or switch appropriately between user queries and assistant replies."],"metadata":{"id":"cO0pDJn2rpRJ"}}]}
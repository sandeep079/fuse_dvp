{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **BYOL: Bootstrap Your Own Latent**\n","\n","### Pre-requisites\n","\n","* Familiarity with contrastive learning frameworks (SimCLR, MoCo)\n","* Understanding of representation learning and CNNs\n","* Knowledge of momentum encoders and projection heads"],"metadata":{"id":"EHK7JAzpm--E"}},{"cell_type":"markdown","source":["Most contrastive learning methods (like SimCLR and MoCo) rely on **negative samples** to avoid collapsing representations. However, **BYOL (Bootstrap Your Own Latent)** proposes a novel approach: **learning good representations without negative samples at all**.\n","\n","> **Analogy**: Imagine two friends learning dance by copying each other’s movements. One leads (online network), and the other follows with stable moves (target network). Over time, the leading friend learns to mimic better, even without a critic.\n","\n","This analogy is crucial because it highlights the core difference: BYOL manages to learn representations by self-supervision, where one part of the network coaches another, eliminating the need for explicitly comparing \"positive\" and \"negative\" examples.\n"],"metadata":{"id":"gNdM3XNfm8bQ"}},{"cell_type":"markdown","source":["# **The Collapsing Problem**\n","In self-supervised learning if a model learns to output a constant representation for all inputs, the loss function could easily be minimized (e.g., by making all embeddings zero) without learning anything useful. This is known as **representation collapse.**\n","\n","If the model always outputs the same feature vector regardless of the input image, it's not actually learning to differentiate anything, rendering the learned representations useless for downstream tasks. This is the central challenge BYOL aims to solve without negative samples.\n","\n","To avoid collapse, most contrastive methods rely on:\n","\n","**Negative samples**:\n","\n","* Explicitly pushing apart representations of different instances.\n","\n","* This is like saying \"If these two images are different, their representations in the latent space must be far apart.\"\n","\n","**Large batch sizes:**\n","* To get enough diverse negative samples in a mini-batch.\n","\n","* The larger the batch, the more distinct negative examples there are for comparison, which helps prevent collapse but demands significant computational resources.\n","\n"],"metadata":{"id":"-nMHUjZ72TBB"}},{"cell_type":"markdown","source":["## **Core Idea**\n","\n","BYOL trains a network to **predict the representation of one augmented view** of an image from **another augmented view**, using two networks:\n","\n","* An **online network** that learns\n","* A **target network** that provides stable targets (not directly trained)\n","\n","> No need for negative pairs. Instead, BYOL prevents representation collapse through a **momentum-updated target network** and a **prediction head**."],"metadata":{"id":"8x8DqWASm3fG"}},{"cell_type":"markdown","source":["\n","## **Architecture Overview**\n","\n","<center>\n","  <img src=\"https://www.researchgate.net/publication/355737346/figure/fig1/AS:1084211217870854@1635507506342/BYOLs-architecture-BYOL-minimizes-a-similarity-loss-between-qthzth-and-sgzx-where-th-and.jpg\" width=70%>\n","</center>\n","\n","### **1. Data Augmentation**\n","\n","Given an image, generate two random augmented views:\n","\n","* $v$: first augmented view\n","* $v'$: second augmented view\n","\n","Typical augmentations include:\n","\n","* Random cropping and resizing\n","* Color jittering\n","* Horizontal flipping\n","* Gaussian blur\n","\n","These transformations help learn invariance by forcing the model to represent the same content under varying conditions.\n","\n","### **2. Online and Target Networks**\n","\n","Both views are passed through two structurally identical but functionally different networks:\n","\n","#### **2.1 Online Network** $(f_\\theta, g_\\theta, q_\\theta)$\n","\n","* **Encoder** $f_{\\theta}$: Backbone network like ResNet.\n","* **Projection Head** $g_{\\theta}$: MLP that maps encoder output to latent representation space.\n","* **Predictor** $q_{\\theta}$: MLP that transforms the projection into a prediction vector.\n","\n","#### **2.2 Target Network** $(f_\\xi, g_\\xi)$\n","\n","* Has the same architecture as the online network (encoder + projection), **but no predictor**.\n","* Not updated via backpropagation.\n","* Updated using **momentum** from the online network:\n","\n","$$\n","\\xi \\leftarrow m \\cdot \\xi + (1 - m) \\cdot \\theta\n","$$\n","\n","Where $m$ is a momentum coefficient (e.g., 0.996). This slow update ensures smoother and more stable targets across training iterations.\n","\n","\n","### **3. Forward Pass Flow**\n","\n","1. **Online branch** processes view $v$:\n","\n","$$\n","y = q_{\\theta}(g_{\\theta}(f_{\\theta}(v)))\n","$$\n","\n","2. **Target branch** processes view $v'$:\n","\n","$$\n","y' = g_{\\xi}(f_{\\xi}(v'))\n","$$\n","\n","> Both $y$ and $y'$ are **L2-normalized** before loss computation.\n","\n","\n","### **4. Loss Function**\n","\n","BYOL uses **Mean Squared Error (MSE)** between the normalized outputs of the online predictor and target encoder:\n","\n","$$\n","\\mathcal{L} = \\left\\| \\text{Normalize}(y) - \\text{Normalize}(y') \\right\\|_2^2\n","$$\n","\n","The total loss is computed symmetrically by also predicting $v$ from $v'$ using the opposite roles.\n","\n","This helps the online network gradually align its predictions to the stable representations of the target network.\n","\n","\n","\n"],"metadata":{"id":"KvGDUh0amiFh"}},{"cell_type":"markdown","source":["## **Why Doesn’t BYOL Collapse?**\n","\n","Despite lacking negative samples, BYOL avoids collapse due to:\n","\n","* The **momentum-updated target network** ensuring temporal consistency\n","* The **predictor network** introducing asymmetry, encouraging non-trivial solutions\n","\n","This combination implicitly regularizes the training process, steering it away from trivial constant outputs.\n","\n","> Empirical results show BYOL performs competitively or better than SimCLR and MoCo, even without using contrastive negatives.\n","\n","\n"],"metadata":{"id":"YKT149_Kmxdi"}},{"cell_type":"markdown","source":["## **Downstream Applications**\n","\n","After training, only the **encoder from the online network** is retained. It can be fine-tuned or used as a feature extractor for:\n","\n","* **Image classification** (linear probe or fine-tuning)\n","* **Object detection**\n","* **Semantic segmentation**\n","* **Medical imaging** or domain-specific transfer tasks"],"metadata":{"id":"YmkGFwe2GXA3"}},{"cell_type":"markdown","source":["\n","\n","## **Advantages of BYOL**\n","\n","| Feature                | BYOL                                 |\n","| ---------------------- | ------------------------------------ |\n","| Negative Samples       | Not required                         |\n","| Network Design         | Online + Momentum Target             |\n","| Risk of Collapse       | Mitigated via momentum and predictor |\n","| Representation Quality | High (often rivals SimCLR/MoCo)      |\n","\n","\n","\n","## **Challenges and Considerations**\n","\n","* **Momentum tuning** is critical for stable learning\n","* **Asymmetry via predictor** is essential — removing it leads to collapse\n","* **Training time** may be longer without negatives, but requires smaller batch sizes\n"],"metadata":{"id":"OP0mavSZmsDy"}},{"cell_type":"markdown","source":["\n","## **Conclusion**\n","\n","**BYOL** challenges the assumption that negative samples are essential for self-supervised learning. With its **momentum-updated target encoder** and **predictor MLP**, BYOL learns rich and transferable representations **purely from positive pairs**.\n","\n","Its architecture has inspired many follow-up models, including:\n","\n","* **SimSiam**: Removes momentum encoder but relies on stop-gradient\n","* **DINO**: Adapts the idea to vision transformers\n","* **VICReg**: Combines variance-invariance-covariance regularization\n","\n","BYOL remains a cornerstone in the evolution of contrastive and non-contrastive self-supervised learning.\n","\n"],"metadata":{"id":"9UX9VgP7mokf"}},{"cell_type":"markdown","source":["## **References**\n","\n","* Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P. H., Buchatskaya, E., ... & Valko, M. (2020).\n","  [Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/abs/2006.07733). *NeurIPS 2020*.\n","\n","* Sik-Ho Tsang. (Feb 13, 2022).\n","  [Review — BYOL: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning](https://sh-tsang.medium.com/review-byol-bootstrap-your-own-latent-a-new-approach-to-self-supervised-learning-6f770a624441).\n","\n","## **Code Tutorial Reference**\n","\n","* **Odom, F.** (2020, November 5). [Easy Self-Supervised Learning with BYOL](https://medium.com/the-dl/easy-self-supervised-learning-with-byol-53b8ad8185d). *The DL – Medium*.\n","\n"],"metadata":{"id":"4OGinN78CHVu"}}]}
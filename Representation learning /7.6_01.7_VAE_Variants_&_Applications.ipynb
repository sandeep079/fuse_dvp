{"cells":[{"cell_type":"markdown","metadata":{"id":"0-cZ9nFoKFHY"},"source":["# **VAE Variants and Applications**\n","\n","### Pre-requisites\n","\n","To follow this lesson, learners should understand:\n","\n","* Basics of **Autoencoders and VAEs**\n","* **Latent space** and **probability distributions**\n","* Neural networks and **optimization**\n","* Basic idea of **generative models**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"tags":["image"],"id":"m42axDIbx-4N"},"source":["## 1. **β-VAE**\n","\n","<center>\n","\n","<img src=\"http://lucas-bechberger.de/wp-content/uploads/2018/12/beta-VAE.png\" width=70%>\n","</center>\n","</br>\n","\n","The **β-VAE** introduces a hyperparameter **β** to control the strength of the **KL divergence** term in the VAE loss function. By increasing β, it encourages the model to learn more **disentangled latent representations**, where each dimension captures an **independent factor** of variation in the data.\n","\n","This makes β-VAE especially useful for applications where **interpretability** of the latent space is important, such as **scientific research** or **representation learning** tasks that benefit from understanding and manipulating individual features."]},{"cell_type":"markdown","source":["## 2. **Conditional VAE (CVAE)**\n","\n","\n","\n","<center>\n","\n","<img src=\"https://www.researchgate.net/publication/365190062/figure/fig2/AS:11431281095388874@1667878234857/Structure-of-the-conditional-variational-autoencoder-CVAE.png\" width=70%>\n","</center>\n","</br>\n","\n","**CVAE** extends the VAE by conditioning both the **encoder and decoder** on additional information, like **class labels or attributes**. This makes the generative process guided by specific conditions, allowing **controlled output generation**.\n","\n","CVAE is widely used in tasks like **conditional image generation**, **style transfer**, and **semi-supervised learning**, where generating specific categories or types of data is essential.\n"],"metadata":{"id":"Xn5mS1pZ2pQB"}},{"cell_type":"markdown","source":["## 3. **VQ-VAE (Vector Quantized VAE)**\n","\n","<center>\n","\n","<img src=\"https://miro.medium.com/v2/1*9GZoBSZPw4VelO2vV9KfDw.png\" width=70%>\n","</center>\n","</br>\n","\n","\n","**VQ-VAE** replaces the continuous latent space with a **discrete codebook** using **vector quantization**. This allows the model to learn **compressed, symbolic representations** more suitable for discrete data domains.\n","\n","It is highly effective in domains like **text**, **audio**, and **high-fidelity image synthesis**, and has been used in advanced models like **OpenAI’s Jukebox** for **music generation**.\n","\n"],"metadata":{"id":"_oZY4tvg2sqg"}},{"cell_type":"markdown","source":["## 4. **Hierarchical VAE**\n","\n","**Hierarchical VAEs** introduce **multiple layers** of latent variables, capturing abstract features at **different levels**. This layered structure allows the model to represent both **high-level** and **fine-grained** information in data.\n","\n","This variant is powerful in modeling **complex, structured data** such as **videos**, **natural scenes**, or **sequential information** where multiple levels of abstraction are necessary.\n"],"metadata":{"id":"q7WJiTGJ2ukz"}},{"cell_type":"markdown","source":["## 5. **VAE-GAN**\n","\n","<center>\n","\n","<img src=\"https://miro.medium.com/v2/1*m5_r0XSfTYyK0Q_NKlfj9w.png\" width=55%>\n","</center>\n","</br>\n","\n","\n","**VAE-GAN** merges the VAE with a **Generative Adversarial Network (GAN)**, combining the encoder-decoder structure with a **discriminator** that encourages more **realistic outputs**.\n","\n","It’s commonly used in tasks requiring **high-quality visual outputs**, such as **photorealistic image generation**, where standard VAEs may produce **blurry results**.\n"],"metadata":{"id":"MU3L2RWX2ywj"}},{"cell_type":"markdown","source":["\n","## 6. **Sparse VAE**\n","\n","**Sparse VAE** encourages the latent representations to be **sparse**—i.e., most values are **zero or inactive**. This helps the model learn **compact**, **meaningful features** with fewer active dimensions.\n","\n","This is particularly useful for applications in **interpretability**, **feature selection**, or **biological data modeling**, where sparse representations often align with **real-world constraints**.\n","\n","\n","\n"],"metadata":{"id":"8hmgNlx620WH"}},{"cell_type":"markdown","source":["## 7. **FactorVAE**\n","\n","\n","**FactorVAE** builds on β-VAE by directly penalizing the **total correlation** in the latent variables, leading to better **disentanglement** by explicitly minimizing **dependencies** between latent dimensions.\n","\n","Its main advantage is producing **disentangled representations** with better **reconstruction quality**, useful in **robotics**, **reasoning**, and **fair AI**.\n","\n"],"metadata":{"id":"YsvrzUhi22WJ"}},{"cell_type":"markdown","source":["## 8. **InfoVAE**\n","\n","**InfoVAE** modifies the VAE objective to retain more **mutual information** between input and latent variables while still **regularizing** the latent space. This balances learning **informative encodings** and **generalization**.\n","\n","It’s beneficial for applications where preserving **detailed input information** is important—such as **image compression**, **rich representation learning**, or **reconstruction-heavy tasks**.\n"],"metadata":{"id":"N0C7vTbo23s9"}},{"cell_type":"markdown","source":["## 9. **TD-VAE (Temporal Difference Variational Autoencoder)**\n","\n","<center>\n","\n","<img src=\"https://ar5iv.labs.arxiv.org/html/1806.03107/assets/figs/VRNN.png\" width=50%>\n","</center>\n","</br>\n","\n","\n","\n","TD-VAE is designed for modeling sequences with long-term dependencies by learning **belief states** that summarize past information and predict future states over variable time intervals. Unlike standard VAEs that focus on reconstructing individual data points, TD-VAE models **temporal dynamics** explicitly, making it well-suited for time series and reinforcement learning tasks.\n","\n","This variant excels in applications requiring **long-term planning** and **state prediction**, such as robotics, video understanding, and any domain where modeling how data evolves over time is crucial."],"metadata":{"id":"xxCTucOK4jtV"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
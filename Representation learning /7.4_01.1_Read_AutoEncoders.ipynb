{"cells":[{"cell_type":"markdown","metadata":{"id":"0-cZ9nFoKFHY"},"source":["# **AutoEncoders**\n","\n","## Pre-requisites\n","\n","To start this lession you must be aware of the following concepts:\n","* Latent Variable Models\n","* Basics of Deep Learning:\n","    * Supervised learning\n","    * Neural Network and Activation Functions\n","    * Gradients and Optimizations\n","\n","## Learning Objectives\n","By the end of this lesson, the students will be able to:\n","- Recall the components visualize the latent space with a real-life example.\n","- Understand properties and applications of autoencoders.\n","- Differentiate the types of autoencoders based on their structure and functionality.\n","\n"]},{"cell_type":"markdown","metadata":{"tags":["image"],"id":"m42axDIbx-4N"},"source":["## Autoencoder and its Components\n","\n","**Autoencoders** are unsupervised neural network architectures designed to learn efficient representations of input data by training the network to reconstruct the input from a compressed form. They work by first encoding the input into a lower-dimensional latent representation, and then decoding it back to a form that closely resembles the original input. Since the input and output are the same, autoencoders do not require labeled data and are trained in an unsupervised manner.\n","\n","\n","<center>\n","<figure>\n","\n","<img src=\"https://i.postimg.cc/HxRW0n7x/Autoencoder.png\" height=\"480\" width=\"620\"></p>\n","<figcaption align=\"center\">Figure 1: Autoencoder with single hidden layer in encoder and decoder</figcaption>\n","</figure>\n","</center>\n","\n","1. **Encoder**: Encoders are a fully connected layer that transforms or compresses the given input ($\\mathbf{x}$) to compressed representation or latent-space representation ($\\mathbf{h}$). It can be represented by an encoding function.\n","$$ \\phi: \\mathbf{x} \\rightarrow \\mathbf{h} $$\n","The above function represents the encoding of input to latent space representation situated in the bottleneck.\n","\n","\n","2. **Latent Space Representation (Compressed Representation)**:\n","   This is the **bottleneck layer** of the autoencoder, where input data is compressed into a **lower-dimensional vector**, often called the **code** or **latent vector**. It captures the most important features of the input and allows the model to group similar inputs close together in the latent space.\n","\n","    <center>\n","    <img src=\"https://i.postimg.cc/kXHbCBmt/Latent-Space.png\" width=60%>  \n","    <figcaption>Figure 2: 2D visualization of latent space showing digit clusters</figcaption>\n","\n","    </center>\n","\n","    The **latent space** is a learned feature space where high-dimensional data is represented compactly, revealing hidden patterns and relationships. The scatter plot above illustrates how the autoencoder organizes data in latent space:\n","\n","    * Each **color** represents a different digit class.\n","    * Similar digits are **clustered closely**, reflecting shared features.\n","    * Dissimilar digits are **clearly separated**, indicating distinct latent representations.\n","    * For instance, digits **0** and **1** appear far apart, while digits **0** and **6** are closer, mirroring their visual similarity.\n","\n","\n","3. **Decoder**: Decoders are a fully connected layer that reconstructs the data from latent space representation to be as close to the original input.  It can be represented by a decoding function $$ \\theta: \\mathbf{h} \\rightarrow \\mathbf{x'} $$ Where,\n"," $\\mathbf{x'}$ is the reconstructed output of the network. Each subsequent layer in the decoder usually has a greater no. of nodes than the previous one.\n"]},{"cell_type":"markdown","metadata":{"id":"5RQVOCSCKFUB"},"source":["## Properties of Autoencoders\n","\n","1. Autoencoders are **unsupervised** in nature as they train on unlabeled data. They are also called self-supervised network.\n","2. They are **data-specific**, meaning that they are efficient at compressing/reconstructing the data they have been trained on.\n","3. They are **lossy**, so the output is a degraded version of input and the exact reconstruction of the original input data cannot be obtained.\n"]},{"cell_type":"markdown","metadata":{"id":"8_uZ0uu24e4w"},"source":["## Types of Autoencoder\n","\n","### Based on Structure\n","> Based on dimension of latent representation($h$) with respect to input dimension($x$)\n","\n","- ## **Undercomplete Autoencoder**\n","\n","    An autoencoder with smaller dimensions of compressed representation(code) than input $h$ < $x$.\n","\n","    <center>\n","    <figure>\n","\n","    <p><img src=\"https://i.postimg.cc/sxWPZSdm/Undercomplete-Autoencoder.png\" height=\"200\" width=\"350\"></p>\n","    <figcaption align=\"center\">Figure 2: Undercomplete Autoencoder Block Diagram </figcaption>\n","    </figure>\n","    </center>\n","\n"," This model minimizes reconstruction error (e.g., mean squared error) to learn a compact representation, rather than directly copying input to the output.\n"," The bottleneck(code) acts as implicit regularization, but explicit regularization (e.g., weight decay, noise in denoising autoencoders) is often used to enhance generalization.\n","\n"," **Applications:** Dimensionality Reduction, Anomaly Detection, and Feature Extraction.\n","\n","- ## **Overcomplete Autoencoder**\n","\n","  An autoencoder with higher dimension of compressed representation(code) than input $h$ > $x$.\n","\n","    <center>\n","    <figure>\n","\n","    <p><img src=\"https://i.postimg.cc/Vv6Dh5tP/Overcomplete-Autoencoder.png\" height=\"220\" width=\"350\"></p>\n","    <figcaption align=\"center\">Figure 3: Overcomplete Autoencoder Block Diagram </figcaption>\n","    </figure>\n","    </center>\n","\n","  Without regularization, it may copy the input to the output, learning trivial features. However, with regularization (e.g., sparsity constraints, dropout), it can learn rich, meaningful representations. Regularization is essential to prevent trivial solutions.\n","  \n","  **Applications:** Sparse Coding and Feature Learning for complex data.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"tags":["image"],"id":"Om_bVHQhx-4s"},"source":["### Based on Functionality\n","\n","> Based on types of neurons in the hidden layer (i.e., latent structure), etc.\n","\n","- ## **Sparse Autoencoders**\n","\n","    These encoders generally have more hidden units than inputs, but only a small number of units are activated to learn the features from the data.\n","\n","    <center>\n","    <figure>\n","\n","    <p><img src=\"https://i.postimg.cc/L6422gGK/Sparse-Autoencoder.png\" height=\"375\" width=\"550\"></p>\n","    <figcaption align='center'>Figure 4: Sparse autoencoder</figcaption>\n","    </figure>\n","    </center>\n","\n","    The sparsity constraint introduced in the hidden layer is to prevent overfitting. This forces model to prevent the output layer copy the input layer.\n","\n","\n","- ## **Convolutional autoencoders**\n","\n","    Instead of using a simple dimensionality technique, these encoders use convolution layers to extract essential features from the input and similar structure for reconstructing it.\n","  \n","    <center>\n","    <figure>\n","\n","    <p><img src=\"https://i.postimg.cc/bNTyq4yT/Convolutional-Autoencoder.png\" height=\"350\" width=\"700\"></p>\n","    <figcaption align='center'>Figure 5: Convolutional autoencoder</figcaption>\n","    </figure>\n","    </center>\n","\n","  The main benefits of having convolution layers are:\n","    - Due to convolution nature, realistic-sized high dimensional images can be well scaled\n","    - Can reconstruct the missing part as well as remove noise from the images\n","\n","\n","\n","- ## **Variational autoencoders**\n","    Variational autoencoders are the generative models, unlike the classical models (sparse, denoising, etc.) autoencoders. VAE introduces probabilistic spin on autoencoders to let them generate new data by sampling.\n","\n","    <center>\n","    <figure>\n","\n","    <p><img src=\"https://i.postimg.cc/mkSyXTQJ/Variational-Autoencoder.png\" height=\"200\" width=\"450\"></p>\n","    <figcaption align='center'>Figure 6: Variational autoencoder</figcaption>\n","    </figure>\n","    </center>\n","\n","  Hence, VAE can act as a generative model like **Generative Adversarial Network (GAN)**, which gives significant control over the modeling of our latent distribution, unlike other models.\n","\n","\n","For the detailed explanation about these encoders, you can refer to this [link](https://iq.opengenus.org/types-of-autoencoder/).\n"]},{"cell_type":"markdown","metadata":{"id":"lHwLeF55CwOY"},"source":["\n","## Applications of Autoencoders\n","\n","1. Autoencoders are primarily used for **dimensionality reduction** or **feature extraction** task.\n","2. They can be used to **generate images** closer to the original input image.\n","3. They can **remove noise** from the images and even compress the images.\n","4. They can remove watermarks from the images, which is called as **neural inpainting**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rGMbPO13KFe8"},"source":["## Key Takeaways\n","\n","* Autoencoders are unsupervised neural network architectures which is trained to replicate its input to output\n","\n","* The components of Autoencoders are Encoder, Compressed Representation and Decoder.\n","* Latent Space is the vector space of compressed representation of higher dimension input vectors.\n","* They help in extracting useful relationships from the input data that we may be unaware of.\n","* Autoencoders are data-specific, unsupervised and lossy in nature.\n","* Undercomplete autoencoder has a code size dimension lesser than the input size and exactly opposite for the overcomplete autoencoder.\n","* In sparse autoencoder, neurons are randomly drop-off in different hidden layers.\n","* In convolutional autoencoder, different convolutional layers are included in the encoder and decoder section.\n","* Variational autoencoders are the generative models where sampling distribution occurs in between encoder and decoder.\n"]},{"cell_type":"markdown","metadata":{"id":"9cFFLVy-KFkH"},"source":["## References\n","\n","- Papers\n","  - Pierre B. (2012), [Autoencoders, Unsupervised Learning, and Deep Architectures](http://proceedings.mlr.press/v27/baldi12a/baldi12a.pdf)\n","    - Refer this paper to understand linear and non-linear autoencoders mathematically.\n","\n","- Books\n","  - Ian Goodfellow, [Deep Learning (Adaptive Computation and Machine Learning series)](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?ie=UTF8&qid=1472485235&sr=8-1&keywords=deep+learning+book)\n","    - Refer [this chapter](https://www.deeplearningbook.org/contents/autoencoders.html) to read more about autoencoders mathematically.\n","\n","- University Lectures\n","  - Jean-Pierre B., [Deep Learning Techniques for Music Generation Autoencoder](http://www-desir.lip6.fr/~briot/cours/unirio2/Slides/dlmg-4-autoencoder.pdf)\n","    - Check this slide to understand how autoencoders can implement in real-world problems.\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}